{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module '_sqlite3'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ModelToSteal import ModelToStealOfficial\n",
    "from solvedataset import SaveSolveDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/ModelStealingPub.pt\"\n",
    "save_path = \"../data/Encodings.pt\"\n",
    "N = 100\n",
    "batch_size = 1\n",
    "\n",
    "dataloader_kwargs = {'batch_size': batch_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module '_sqlite3'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "class DataStealer():\n",
    "    def __init__(self, model_to_steal, path_to_images, path_to_vectors):\n",
    "        self.model_to_steal = model_to_steal\n",
    "        self.path_to_images = path_to_images\n",
    "        \n",
    "        self.iterations_to_denoise = 1\n",
    "        self.save_solve_dataset = SaveSolveDataset(path_to_vectors)\n",
    "\n",
    "    def prepare_dataloader(self):\n",
    "        # TODO Popracuj nad data augmentation\n",
    "        dataset = torch.load(self.path_to_images)\n",
    "        return torch.utils.data.DataLoader(dataset, dataloader_kwargs)\n",
    "\n",
    "\n",
    "    def get_one_embedding(self, id, img, label):\n",
    "        # TODO Zrób denoise\n",
    "        encoding = self.model_to_steal.get_embeddings(img)\n",
    "        self.save_solve_dataset.add(id, img, label, encoding)\n",
    "\n",
    "    def encode_data(self):\n",
    "        dataloader = self.prepare_dataloader()\n",
    "\n",
    "        for id, img, label in enumarate(dataloader):\n",
    "            self.get_one_embedding(id, img, label)\n",
    "\n",
    "        self.save_solve_dataset.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Wielokrotnie wysyłaj pliki ze state-of-art żeby oszacować noise\n",
    "    def estimate_noise(state_of_art):\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    # Przygotuj pierwsze 10 obrazków na state-of-art do sprawdzania noise\n",
    "    def prepare_state_of_art(dataset):\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    # Wysyłaj kolejne N obrazków po K razy, żeby zredukować szum\n",
    "    # Następnie zapisuje wynik w wynikowym_datasecie\n",
    "    def send_data(dataset):\n",
    "        \n",
    "        # TODO\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_steal():\n",
    "    K = 1\n",
    "\n",
    "    # Spreparuj dataset do wykradania\n",
    "    dataset = prepare_dataset()\n",
    "\n",
    "    # Przygotuj pierwsze 10 plikow na state-of-the-art\n",
    "\n",
    "    # Wysyłaj kolejne 100 obrazków po K razy ze spreparowanego datasetu\n",
    "\n",
    "    # Oszacuj wariancję na podstawie state-of-art i zaktualizuj K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader():\n",
    "    # TODO Popracuj nad data augmentation\n",
    "    dataset = torch.load(data_path)\n",
    "    return torch.utils.data.DataLoader(dataset, dataloader_kwargs)\n",
    "\n",
    "# Przygotuj pierwsze 10 obrazków na state-of-art do sprawdzania noise\n",
    "def prepare_state_of_art(dataset):\n",
    "    # TODO\n",
    "    pass\n",
    "\n",
    "# Wysyłaj kolejne N obrazków po K razy, żeby zredukować szum\n",
    "# Następnie zapisuje wynik w wynikowym_datasecie\n",
    "def send_data(dataset, K):\n",
    "    \n",
    "    # TODO\n",
    "    pass\n",
    "\n",
    "# Wielokrotnie wysyłaj pliki ze state-of-art żeby oszacować noise\n",
    "def estimate_noise(state_of_art):\n",
    "    # TODO\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
